{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84fe28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jdts\\anaconda3\\envs\\emotionram\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2 as cv\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import RMSprop\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from data_loaders import CAERSDataset\n",
    "from utils import get_transform, accuracy, accuracy_julia\n",
    "from model import model_generator\n",
    "from tqdm import tqdm\n",
    "import os.path as osp\n",
    "from keras.models import load_model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f15591bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '.\\models\\\\faces_19_95.01295733262594.pth'\n",
    "model = torch.load(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9be272cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") ## Se a maquina não tiver GPU o teste será rodado na CPU\n",
    "\n",
    "test_dataset = CAERSDataset('data/CAER-S', 'data/test.txt', transforms=get_transform(train=False))\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "loss = CrossEntropyLoss()\n",
    "opt = RMSprop(model.parameters(), lr=3e-3)\n",
    "lr_scheduler = StepLR(opt, 60, 0.4)\n",
    "\n",
    "best_model_acc = 0.0\n",
    "lowest_loss = 1\n",
    "count_ep = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f0c92c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 448/1532 [02:51<06:55,  2.61it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m      6\u001b[0m     \u001b[39mwith\u001b[39;00m tqdm(total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(test_dataloader), position\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m pbar_1:\n\u001b[1;32m----> 7\u001b[0m         \u001b[39mfor\u001b[39;00m data, label \u001b[39min\u001b[39;00m \u001b[39miter\u001b[39m(test_dataloader):\n\u001b[0;32m      8\u001b[0m             face \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mface\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m             preds \u001b[39m=\u001b[39m model(face\u001b[39m.\u001b[39mto(device))\n",
      "File \u001b[1;32mc:\\Users\\jdts\\anaconda3\\envs\\emotionram\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\jdts\\anaconda3\\envs\\emotionram\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\jdts\\anaconda3\\envs\\emotionram\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\jdts\\anaconda3\\envs\\emotionram\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\jdts\\Documents\\TCC\\EmotionRAM-Faces\\data_loaders.py:39\u001b[0m, in \u001b[0;36mCAERSDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     35\u001b[0m x1, y1, x2, y2 \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39mceil(\u001b[39mfloat\u001b[39m(sample[\u001b[39m2\u001b[39m])), math\u001b[39m.\u001b[39mceil(\u001b[39mfloat\u001b[39m(sample[\u001b[39m3\u001b[39m])), math\u001b[39m.\u001b[39mceil(\u001b[39mfloat\u001b[39m(sample[\u001b[39m4\u001b[39m])), math\u001b[39m.\u001b[39mceil(\u001b[39mfloat\u001b[39m(sample[\u001b[39m5\u001b[39m]))\n\u001b[0;32m     37\u001b[0m im \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(path)\n\u001b[1;32m---> 39\u001b[0m face \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39;49mcrop((x1, y1, x2, y2))\n\u001b[0;32m     41\u001b[0m data \u001b[39m=\u001b[39m {\n\u001b[0;32m     42\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mface\u001b[39m\u001b[39m'\u001b[39m: face\n\u001b[0;32m     43\u001b[0m }\n\u001b[0;32m     45\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jdts\\anaconda3\\envs\\emotionram\\lib\\site-packages\\PIL\\Image.py:1233\u001b[0m, in \u001b[0;36mImage.crop\u001b[1;34m(self, box)\u001b[0m\n\u001b[0;32m   1230\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCoordinate \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlower\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is less than \u001b[39m\u001b[39m'\u001b[39m\u001b[39mupper\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1231\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m-> 1233\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m   1234\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_crop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mim, box))\n",
      "File \u001b[1;32mc:\\Users\\jdts\\anaconda3\\envs\\emotionram\\lib\\site-packages\\PIL\\ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(msg)\n\u001b[0;32m    268\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[1;32m--> 269\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[0;32m    270\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    271\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval() ## modo teste e validação\n",
    "running_loss = 0.0\n",
    "test_outs, test_gts = [],[] ##malu\n",
    "\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(test_dataloader), position=1, leave=True) as pbar_1:\n",
    "        for data, label in iter(test_dataloader):\n",
    "            face = data['face']\n",
    "\n",
    "            preds = model(face.to(device))\n",
    "            preds = preds.to('cpu')\n",
    "\n",
    "            running_loss = loss(preds, label)\n",
    "            test_outs.extend(torch.argmax(preds, dim=1))##malu\n",
    "            test_gts.extend(label.to('cpu'))##malu\n",
    "            pbar_1.update(1)\n",
    "            #image =  cv.imread(face)\n",
    "            #cv.imshow('teste',image)\n",
    "            #cv.waitkey(0)\n",
    "        \n",
    "            \n",
    "                   \n",
    "\n",
    "    test_acc = accuracy_julia(test_outs,test_gts)\n",
    "    #print(f'test :: acc {test_acc} :: loss {running_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebde74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib import request\n",
    "\n",
    "def salvar_imagem(imagem, nome_arquivo, pasta):\n",
    "    # Verifica se a pasta existe\n",
    "    if not os.path.exists(pasta):\n",
    "        # Cria a pasta se não existir\n",
    "        os.makedirs(pasta)\n",
    "\n",
    "    # Define o caminho completo para o arquivo\n",
    "    caminho_arquivo = os.path.join(pasta, nome_arquivo)\n",
    "\n",
    "    # Faz o download da imagem\n",
    "    #request.urlretrieve(url, caminho_arquivo)\n",
    "    cv.imwrite(caminho_arquivo,imagem)\n",
    "\n",
    "    print(f'A imagem {nome_arquivo} foi salva em {pasta}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e56adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def set_emotion(label):\n",
    "\n",
    "    if label == '0' :\n",
    "        emotion = 'Angry'\n",
    "    elif label == '1':\n",
    "        emotion = 'Disgust'\n",
    "    elif label == '2':\n",
    "        emotion = 'Fear'\n",
    "    elif label == '3':\n",
    "        emotion = 'Happy'\n",
    "    elif label == '4':\n",
    "        emotion = 'Neutral'\n",
    "    elif label == '5':\n",
    "        emotion = 'Sad'\n",
    "    elif label == '6':\n",
    "        emotion = 'Surprise'\n",
    "    return emotion\n",
    "    \n",
    "        \n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c350b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_quali = open(\"data\\\\test.txt\")\n",
    "print(\"ok1\")\n",
    "file_content = data_quali.readlines()\n",
    "i=0\n",
    "#dado = []\n",
    "num = ''\n",
    "emotion = ''\n",
    "\n",
    "for i in range(len(file_content)):\n",
    "    dado = file_content[i].split(',')\n",
    "    path_image = \"data\\CAER-S\\\\\" + dado[0]\n",
    "    ground_truth = dado[1]\n",
    "\n",
    "    image = cv.imread(path_image)\n",
    "    aux = dado[0].split('/')\n",
    "    preds = str(test_outs[i].numpy())\n",
    "\n",
    "\n",
    "    emotion_GT = str(set_emotion(ground_truth))\n",
    "    emption_Pred =str(set_emotion(preds))\n",
    "    name_image = str(aux[2]) + emotion_GT + emption_Pred + '.png'\n",
    "    \n",
    "    salvar_imagem(image, name_image,\"imagens_quali\")\n",
    "    #cv.imshow(ground_truth,image)\n",
    "    #cv.waitKey(0)\n",
    "    \n",
    "    #print(emotion_GT, emption_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd7134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
