{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2 as cv\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import RMSprop\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from data_loaders import CAERSDataset\n",
    "from utils import get_transform, accuracy, accuracy_julia\n",
    "from model import model_generator\n",
    "from tqdm import tqdm\n",
    "import os.path as osp\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "captura = cv.VideoCapture(0)\n",
    "model_path = '.\\models\\\\faces_19_95.01295733262594.pth'\n",
    "model = torch.load(model_path)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") ## Se a maquina não tiver GPU o teste será rodado na CPU\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "opt = RMSprop(model.parameters(), lr=3e-3)\n",
    "lr_scheduler = StepLR(opt, 60, 0.4)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ret, frame = captura.read()\n",
    "gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 2)\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,w,h = faces[0]\n",
    "print(x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_ = frame[y:y+h, x:x+w, :] # y+ h e x+w\n",
    "plt.imshow(frame_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(frame_)\n",
    "frame__ = torch.asarray(frame_)\n",
    "print(type(frame__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame_.shape, frame__.shape, torch.unsqueeze(frame__, dim=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(frame__.to(device))\n",
    "preds = preds.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(torch.unsqueeze(frame__, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.disable_v2_behavior()\n",
    "#(x,y),(x+w,y+h)\n",
    "\n",
    "while(1):\n",
    "\n",
    "    ret, frame = captura.read()\n",
    "    #cv.imshow(\"Video\", frame)\n",
    "    # convert to grayscale of each frames\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # read haacascade to detect faces in input image\n",
    "    face_cascade = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "        # detects faces in the input image\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 2)\n",
    "\n",
    "    #face_tensor = tf.convert_to_tensor(faces)\n",
    "    #face_tensor = np.load(faces.decode())\n",
    "    \n",
    "\n",
    "    print('Number of detected faces:', len(faces))\\\n",
    "\n",
    "        # loop over all the detected faces\n",
    "    for (x,y,w,h) in faces:\n",
    "        ret, frame = captura.read()\n",
    "        #face = tf.convert_to_tensor(faces, dtype=None, dtype_hint=None, name=None)\n",
    "        #preds = model(frame.to(device))\n",
    "        #preds = preds.to('cpu')\n",
    "          \n",
    "        # To draw a rectangle around the detected face  \n",
    "        \n",
    "        face_cut =  frame[y:y+h, x: x+w]\n",
    "        preds = model(torch.unsqueeze(face_cut, dim=0))\n",
    "        preds = model(face_cut.to(device))\n",
    "        preds = preds.to('cpu')\n",
    "        image= cv.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        cv.putText(image,preds, (x, y-10), cv.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "\n",
    "        # Display an image in a window\n",
    "        cv.imshow('emotionRAM',image)\n",
    "\n",
    "        k = cv.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "           break\n",
    "\n",
    "captura.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotionram",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
